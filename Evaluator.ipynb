{"cells":[{"cell_type":"code","source":["\nbook_url = 'http://www2.informatik.uni-freiburg.de/~cziegler/BX/BX-CSV-Dump.zip'\ndata_path = '/dbfs/FileStore/data'"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["import urllib\nbook_crossing = urllib.urlretrieve (book_url, 'book_crossing.zip')"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["import zipfile\n\nwith zipfile.ZipFile('/dbfs/FileStore/book_crossing.zip', \"r\") as z:\n    z.extractall(data_path)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["import os\nos.listdir(data_path)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["import pandas as pd\nratings_df = pd.read_csv(\"/dbfs/FileStore/data/BX-Book-Ratings.csv\", header=0,sep=';', error_bad_lines=False)\ncolu = [\"ISBN\",\"Book-Title\",\"Book-Author\"]\nbooks_df = pd.read_csv(\"/dbfs/FileStore/data/BX-Books.csv\", header=0,sep=';', error_bad_lines=False,usecols=colu)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["complete_df=ratings_df.merge(books_df)\ncomplete_df['itemID'] = complete_df['ISBN'].astype('category').cat.codes"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["complete_df.columns"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["without_implicit_df = complete_df[complete_df['Book-Rating']!= 0]\nwithout_explicit_df = complete_df[complete_df['Book-Rating']==0]"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["uire = sqlContext.createDataFrame(without_implicit_df).rdd.map(lambda x: (x[0],x[5],x[2]))"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["uire.take(3)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["#ratings_rdd = sqlContext.createDataFrame(pandas_df).rdd.map(tuple)\n#books_rdd = sqlContext.createDataFrame(pandas_df).rdd.map(tuple)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["training,validation,test = uire.randomSplit([6.0,2.0,2.0],seed = 26)\nvalidation_blank = validation.map(lambda x: (x[0],x[1]))\ntest_blank = test.map(lambda x: (x[0],x[1]))\n"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\nranks = [4,7,10,13,16,19,22,28,32]\nnumIterations = 10\nMSElist = []\nfor rank in ranks:\n  model = ALS.train(training, rank, numIterations)\n  predictions = model.predictAll(validation_blank).map(lambda z: ((z[0],z[1]),z[2]))\n  rates_and_predictions = validation.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n  MSE = rates_and_predictions.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n  MSElist.append(MSE)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["for MSE in MSElist:\n  print MSE**.5"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["from pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.recommendation import ALS\nfrom pyspark.sql import Row\n\nals = ALS(maxIter=10, regParam=0.01, userCol=\"User-ID\", itemCol=\"itemID\", ratingCol=\"Book-Rating\")\n#User-ID Book-Rating itemID Book-Rating"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["uire_df = spark.createDataFrame(without_implicit_df)\n(training_df, test_df) = uire_df.randomSplit([0.8, 0.2])\nmodel_2 = als.fit(training_df)\npredictions_2 = model_2.transform(test_df)\npredictions_2 = predictions_2.na.drop(subset='prediction')\nevaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"Book-Rating\",\n                                predictionCol=\"prediction\")\nrmse = evaluator.evaluate(predictions_2)\nprint(\"Root-mean-square error = \" + str(rmse))"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["predictions_2.take(3)"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["from surprise import SVD\nfrom surprise import Dataset\nfrom surprise import evaluate, print_perf\nfrom surprise import Reader"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["explicit_df = complete_df[complete_df['Book-Rating']>0]"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["explicit_small_df = explicit_df.ix[:len(explicit_df)*1.3]"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["data_for_svd = explicit_small_df[['User-ID','itemID','Book-Rating']]\ndata_for_svd.to_csv('/dbfs/FileStore/data/ratings_for_svd.csv',sep=';',index=False)"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["lol = Reader(rating_scale=(1,10),sep=';',line_format=('user item rating'),skip_lines=1)\ndata = Dataset.load_from_file('/dbfs/FileStore/data/ratings_for_svd.csv',reader=lol)"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["data.split(n_folds=3)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["algo = SVD()"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["perf = evaluate(algo, data, measures=['RMSE', 'MAE'])"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["complete_df['Book-Rating'] = complete_df['Book-Rating'].replace([0],9)"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["complete_adjusted_df = spark.createDataFrame(complete_df)"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["als = ALS(maxIter=10, regParam=0.01, userCol=\"User-ID\", itemCol=\"itemID\", ratingCol=\"Book-Rating\")\n(training_df, test_df) = complete_adjusted_df.randomSplit([0.8, 0.2])\nmodel_3 = als.fit(training_df)\npredictions_3 = model_3.transform(test_df)\npredictions_3 = predictions_3.na.drop(subset='prediction')\nevaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"Book-Rating\",\n                                predictionCol=\"prediction\")\nrmse = evaluator.evaluate(predictions_3)\nprint(\"Root-mean-square error = \" + str(rmse))"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["One experiment to be performed is to bring in the Location data of users, and create relational increments based on distance between users using any standard distance metric; to form user neighborhoods and the inverse of these measures to create better serendipity in the system (I believe relevant variety can be found through physical distance and implicit cultural divides; while retaining the same instinctual human likes / dislikes)"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["If online evaluation was possible; I could measure the success of different algorithims by the Click Through Rate and Conversion Rate; perhaps if the CTR was high and the CR was low; I may need to find more ways to increase serendipity or diversity."],"metadata":{},"outputs":[],"execution_count":30}],"metadata":{"name":"Evaluator","notebookId":1649847827897293},"nbformat":4,"nbformat_minor":0}
